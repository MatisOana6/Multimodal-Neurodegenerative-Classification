{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)  \n",
        "print(torch.cuda.is_available())  \n",
        "print(torch.cuda.current_device())  \n",
        "print(torch.cuda.get_device_name(0)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install opencv-python-headless\n",
        "%pip install opencv-python\n",
        "%pip install scikit-image\n",
        "%pip install scikit-learn\n",
        "%pip install tqdm\n",
        "%pip install sympy==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPCk7WN9q1LZ",
        "outputId": "71fffc9c-917d-44ce-e22a-bd2b15bffe82"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=5):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "\n",
        "        for name, param in self.resnet.named_parameters():\n",
        "            if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n",
        "\n",
        "\n",
        "\n",
        "class ResNet101_MRI(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=5):\n",
        "        super(ResNet101_MRI, self).__init__()\n",
        "        self.resnet = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        for name, param in self.resnet.named_parameters():\n",
        "            if \"layer2\" in name or \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_model(path, model_class):\n",
        "    model = model_class(pretrained=False, num_classes=5)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    return model.to(device).eval()\n",
        "\n",
        "model_axial_r50 = load_model(\"ResNet_Alzheimer_Axial_Multiclass.pth\", ResNetModel)\n",
        "model_axial_r101 = load_model(\"ResNet101_Alzheimer_Axial_Multiclass.pth\", ResNet101_MRI)\n",
        "model_sag_r50 = load_model(\"ResNet_Alzheimer_Sagittal_Multiclass.pth\", ResNetModel)\n",
        "model_sag_r101 = load_model(\"ResNet101_Alzheimer_Sagittal_Multiclass.pth\", ResNet101_MRI)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "\n",
        "train_dir1 = 'D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Train/'\n",
        "train_dir2 = 'D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train/'\n",
        "\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "dataset1 = datasets.ImageFolder(root=train_dir1, transform=simple_transform)\n",
        "dataset2 = datasets.ImageFolder(root=train_dir2, transform=simple_transform)\n",
        "\n",
        "combined_dataset = ConcatDataset([dataset1, dataset2])\n",
        "combined_loader = DataLoader(combined_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "\n",
        "for data, _ in combined_loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Std: {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.2192, 0.2192, 0.2192], std=[0.2474, 0.2474, 0.2474])  \n",
        "])\n",
        "\n",
        "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]\n",
        "\n",
        "def predict_dual_view(axial_path, sagittal_path, w_a50=0.25, w_a101=0.25, w_s50=0.25, w_s101=0.25):\n",
        "    axial_img = Image.open(axial_path).convert(\"RGB\")\n",
        "    sagittal_img = Image.open(sagittal_path).convert(\"RGB\")\n",
        "\n",
        "    axial_tensor = transform(axial_img).unsqueeze(0).to(device)\n",
        "    sagittal_tensor = transform(sagittal_img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "        out_a50 = model_axial_r50(axial_tensor)\n",
        "        out_a101 = model_axial_r101(axial_tensor)\n",
        "        out_s50 = model_sag_r50(sagittal_tensor)\n",
        "        out_s101 = model_sag_r101(sagittal_tensor)\n",
        "\n",
        "        final_output = (\n",
        "            w_a50 * out_a50 +\n",
        "            w_a101 * out_a101 +\n",
        "            w_s50 * out_s50 +\n",
        "            w_s101 * out_s101\n",
        "        )\n",
        "\n",
        "        softmax_scores = torch.nn.functional.softmax(final_output, dim=1)\n",
        "        pred_idx = torch.argmax(softmax_scores, dim=1).item()\n",
        "\n",
        "    return pred_idx, softmax_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def find_matching_pairs(axial_root, sagittal_root):\n",
        "    matches = []\n",
        "\n",
        "    for label in os.listdir(axial_root):\n",
        "        axial_class_dir = os.path.join(axial_root, label)\n",
        "        sagittal_class_dir = os.path.join(sagittal_root, label)\n",
        "\n",
        "        if not os.path.isdir(axial_class_dir) or not os.path.isdir(sagittal_class_dir):\n",
        "            continue\n",
        "\n",
        "        axial_files = os.listdir(axial_class_dir)\n",
        "        sagittal_files = os.listdir(sagittal_class_dir)\n",
        "\n",
        "        sagittal_set = set(sagittal_files)\n",
        "\n",
        "        for afile in axial_files:\n",
        "            expected_sagittal = afile.replace(\"Axial\", \"Sagittal\")\n",
        "            if expected_sagittal in sagittal_set:\n",
        "                axial_path = os.path.join(axial_class_dir, afile)\n",
        "                sagittal_path = os.path.join(sagittal_class_dir, expected_sagittal)\n",
        "                matches.append((label, axial_path, sagittal_path))\n",
        "\n",
        "    return matches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "axial_dir = \"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Test/\"\n",
        "sagittal_dir = \"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test/\"\n",
        "output_csv = \"D:/Licenta/rezultate_dualview.csv\"\n",
        "\n",
        "pairs = find_matching_pairs(axial_dir, sagittal_dir)\n",
        "print(f\"Total perechi găsite: {len(pairs)}\\n\")\n",
        "\n",
        "header = [\"TrueLabel\", \"PredictedLabel\", \"AxialPath\", \"SagittalPath\"] + class_names\n",
        "\n",
        "rows = []\n",
        "correct = 0\n",
        "\n",
        "for idx, (true_label, axial_img_path, sagittal_img_path) in enumerate(pairs):\n",
        "    pred_idx, probs = predict_dual_view(axial_img_path, sagittal_img_path)\n",
        "    predicted_label = class_names[pred_idx]\n",
        "    prob_values = [round(p.item(), 4) for p in probs[0]]\n",
        "\n",
        "    rows.append([true_label, predicted_label, axial_img_path, sagittal_img_path] + prob_values)\n",
        "\n",
        "    if predicted_label == true_label:\n",
        "        correct += 1\n",
        "\n",
        "    print(f\"#{idx+1}\")\n",
        "    print(f\"GT : {true_label}\")\n",
        "    print(f\"Pred: {predicted_label}\")\n",
        "    for i, val in enumerate(prob_values):\n",
        "        print(f\"  {class_names[i]:<5}: {val:.4f}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "acc = correct / len(pairs) * 100\n",
        "print(f\"\\n Accuracy pe perechi: {acc:.2f}%\")\n",
        "\n",
        "with open(output_csv, \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(f\"\\n Rezultatele au fost salvate în:\\n{output_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "true_labels = [label for label, _, _ in pairs]\n",
        "pred_labels = [row[1] for row in rows]  \n",
        "\n",
        "cm = confusion_matrix(true_labels, pred_labels, labels=class_names)\n",
        "\n",
        "class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(class_names, class_accuracy * 100, color='skyblue')\n",
        "plt.ylim(0, 105)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Accuracy pe clasă (dual-view ensemble)\")\n",
        "\n",
        "for bar, acc in zip(bars, class_accuracy):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, acc * 100 + 1, f\"{acc * 100:.2f}%\", ha='center')\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class DualViewResNet(nn.Module):\n",
        "    def __init__(self, num_classes=5, pretrained=True):\n",
        "        super(DualViewResNet, self).__init__()\n",
        "\n",
        "        self.resnet_axial = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        self.resnet_sagittal = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "\n",
        "        self.resnet_axial.fc = nn.Identity()\n",
        "        self.resnet_sagittal.fc = nn.Identity()\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(4096, 512), \n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, axial_img, sagittal_img):\n",
        "        feat_axial = self.resnet_axial(axial_img)\n",
        "        feat_sagittal = self.resnet_sagittal(sagittal_img)\n",
        "\n",
        "        combined = torch.cat((feat_axial, feat_sagittal), dim=1)\n",
        "        output = self.classifier(combined)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class DualViewDataset(Dataset):\n",
        "    def __init__(self, pairs, transform=None, class_to_idx=None):\n",
        "        self.pairs = pairs\n",
        "        self.transform = transform\n",
        "        self.class_to_idx = class_to_idx or {name: idx for idx, name in enumerate(sorted({label for label, _, _ in pairs}))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, axial_path, sagittal_path = self.pairs[idx]\n",
        "\n",
        "        assert os.path.exists(axial_path), f\"Axial image not found: {axial_path}\"\n",
        "        assert os.path.exists(sagittal_path), f\"Sagittal image not found: {sagittal_path}\"\n",
        "\n",
        "        axial_img = Image.open(axial_path).convert('RGB')\n",
        "        sagittal_img = Image.open(sagittal_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            axial_img = self.transform(axial_img)\n",
        "            sagittal_img = self.transform(sagittal_img)\n",
        "\n",
        "        label_idx = self.class_to_idx[label]\n",
        "        return axial_img, sagittal_img, label_idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((224, 224)),  \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.2192]*3, std=[0.2474]*3)\n",
        "])\n",
        "\n",
        "axial_dir = \"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Train/\"\n",
        "sagittal_dir = \"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train/\"\n",
        "pairs = find_matching_pairs(axial_dir, sagittal_dir)\n",
        "\n",
        "assert len(pairs) > 0, \"No matching image pairs found!\"\n",
        "\n",
        "dual_dataset = DualViewDataset(pairs, transform=transform)\n",
        "dual_loader = DataLoader(dual_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DualViewResNet(num_classes=5, pretrained=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import copy\n",
        "\n",
        "def train_dualview_model(model, train_loader, val_loader, num_epochs=10, lr=1e-4, patience=7, save_path=\"best_dualview.pth\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
        "    scaler = GradScaler() \n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    best_loss = float(\"inf\")\n",
        "    best_model = None\n",
        "    no_improve_epochs = 0\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss, preds_all, labels_all = 0.0, [], []\n",
        "\n",
        "        for axial_img, sagittal_img, labels in train_loader:\n",
        "            axial_img, sagittal_img, labels = axial_img.to(device), sagittal_img.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():\n",
        "                outputs = model(axial_img, sagittal_img)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            preds_all += torch.argmax(outputs, dim=1).cpu().tolist()\n",
        "            labels_all += labels.cpu().tolist()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = accuracy_score(labels_all, preds_all)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        val_running_loss, val_preds, val_labels = 0.0, [], []\n",
        "        with torch.no_grad():\n",
        "            for axial_img, sagittal_img, labels in val_loader:\n",
        "                axial_img, sagittal_img, labels = axial_img.to(device), sagittal_img.to(device), labels.to(device)\n",
        "                with autocast():\n",
        "                    outputs = model(axial_img, sagittal_img)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                val_running_loss += loss.item()\n",
        "                val_preds += torch.argmax(outputs, dim=1).cpu().tolist()\n",
        "                val_labels += labels.cpu().tolist()\n",
        "\n",
        "        val_loss = val_running_loss / len(val_loader)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        scheduler.step(epoch + 1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} — Train Loss: {train_loss:.4f}, Acc: {train_acc*100:.2f}% | Val Loss: {val_loss:.4f}, Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            torch.save(best_model, save_path)\n",
        "            print(f\"  Saved new best model at epoch {epoch+1}\")\n",
        "            no_improve_epochs = 0\n",
        "        else:\n",
        "            no_improve_epochs += 1\n",
        "            if no_improve_epochs >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    print(f\"\\nTraining finished. Best model saved to: {save_path}\")\n",
        "    return train_losses, val_losses, train_accs, val_accs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_pairs, val_pairs = train_test_split(pairs, test_size=0.2, stratify=[x[0] for x in pairs], random_state=42)\n",
        "\n",
        "train_set = DualViewDataset(train_pairs, transform)\n",
        "val_set = DualViewDataset(val_pairs, transform)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "model = DualViewResNet(num_classes=5, pretrained=True)\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs = train_dualview_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs=20,\n",
        "    lr=5e-5,\n",
        "    patience=10,\n",
        "    save_path=\"best_dualview_model.pth\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 6), dpi=100)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Train Loss', color='red')\n",
        "    plt.plot(epochs, val_losses, label='Validation Loss', color='orange')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss per Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, [a * 100 for a in train_accs], label='Train Accuracy', color='green')\n",
        "    plt.plot(epochs, [a * 100 for a in val_accs], label='Validation Accuracy', color='blue')\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Accuracy per Epoch\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.suptitle(\"DualView Model Training Progress\", fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_training_history(train_losses, val_losses, train_accs, val_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def evaluate_and_plot_confusion_matrix(model, test_loader, class_names, checkpoint_path=\"best_dualview_model.pth\"):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for axial_img, sagittal_img, labels in test_loader:\n",
        "            axial_img, sagittal_img = axial_img.to(device), sagittal_img.to(device)\n",
        "            outputs = model(axial_img, sagittal_img)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds += preds.cpu().tolist()\n",
        "            all_labels += labels.tolist()\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    return cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]  \n",
        "\n",
        "model = DualViewResNet(num_classes=5, pretrained=False)\n",
        "evaluate_and_plot_confusion_matrix(model, val_loader, class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "\n",
        "def show_random_dual_predictions(model, test_dataset, num_images=12, cols=4, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    total_images = len(test_dataset)\n",
        "    num_images = min(num_images, total_images)\n",
        "    indices = random.sample(range(total_images), num_images)\n",
        "\n",
        "    correct_list = []\n",
        "    wrong_list = []\n",
        "\n",
        "    for idx in indices:\n",
        "        axial_img, sagittal_img, label = test_dataset[idx]\n",
        "        input_axial = axial_img.unsqueeze(0).to(device)\n",
        "        input_sagittal = sagittal_img.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "            outputs = model(input_axial, input_sagittal)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "\n",
        "        pred_idx = pred.item()\n",
        "\n",
        "        def denorm(tensor_img):\n",
        "            img = tensor_img.cpu().numpy().transpose((1, 2, 0))\n",
        "            mean = np.array([0.2192]*3)\n",
        "            std = np.array([0.2474]*3)\n",
        "            img = img * std + mean\n",
        "            img = np.clip(img, 0, 1)\n",
        "            return img\n",
        "\n",
        "        entry = {\n",
        "            'axial': denorm(axial_img),\n",
        "            'sagittal': denorm(sagittal_img),\n",
        "            'pred': class_names[pred_idx],\n",
        "            'true': class_names[label],\n",
        "            'is_correct': pred_idx == label\n",
        "        }\n",
        "\n",
        "        if entry['is_correct']:\n",
        "            correct_list.append(entry)\n",
        "        else:\n",
        "            wrong_list.append(entry)\n",
        "\n",
        "    all_entries = wrong_list + correct_list\n",
        "    total = len(all_entries)\n",
        "    rows = total\n",
        "    fig, axes = plt.subplots(rows, 2, figsize=(8, rows * 3))\n",
        "\n",
        "    if rows == 1: \n",
        "        axes = [axes]\n",
        "\n",
        "    for i, entry in enumerate(all_entries):\n",
        "       \n",
        "        axes[i][0].imshow(entry['axial'])\n",
        "        axes[i][0].set_title(f\"Axial\\nPred: {entry['pred']} | True: {entry['true']}\",\n",
        "                             color='green' if entry['is_correct'] else 'red')\n",
        "        axes[i][0].axis('off')\n",
        "\n",
        "        axes[i][1].imshow(entry['sagittal'])\n",
        "        axes[i][1].set_title(f\"Sagittal\\nPred: {entry['pred']} | True: {entry['true']}\",\n",
        "                             color='green' if entry['is_correct'] else 'red')\n",
        "        axes[i][1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"Total image pairs shown: {total}\")\n",
        "    print(f\"Correct predictions: {len(correct_list)}\")\n",
        "    print(f\"Wrong predictions:  {len(wrong_list)}\")\n",
        "\n",
        "    if wrong_list:\n",
        "        print(\"\\n Wrong predictions detail:\")\n",
        "        for idx, entry in enumerate(wrong_list, start=1):\n",
        "            print(f\"  {idx}. Predicted: {entry['pred']} | Actual: {entry['true']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_random_dual_predictions(model, val_set, num_images=100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

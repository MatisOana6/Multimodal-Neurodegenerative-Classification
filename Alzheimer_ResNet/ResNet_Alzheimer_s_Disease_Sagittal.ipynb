{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)  \n",
        "print(torch.cuda.is_available())  \n",
        "print(torch.cuda.current_device())  \n",
        "print(torch.cuda.get_device_name(0)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install opencv-python-headless\n",
        "%pip install opencv-python\n",
        "%pip install scikit-image\n",
        "%pip install scikit-learn\n",
        "%pip install tqdm\n",
        "%pip install sympy==1.13.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dir = 'D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train/'\n",
        "\n",
        "\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "temp_dataset = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
        "temp_loader = DataLoader(temp_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "mean = 0.\n",
        "std = 0.\n",
        "nb_samples = 0.\n",
        "\n",
        "for data, _ in temp_loader:\n",
        "    batch_samples = data.size(0)\n",
        "    data = data.view(batch_samples, data.size(1), -1)\n",
        "    mean += data.mean(2).sum(0)\n",
        "    std += data.std(2).sum(0)\n",
        "    nb_samples += batch_samples\n",
        "\n",
        "mean /= nb_samples\n",
        "std /= nb_samples\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Std: {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPCk7WN9q1LZ",
        "outputId": "71fffc9c-917d-44ce-e22a-bd2b15bffe82"
      },
      "outputs": [],
      "source": [
        "mean_vals = mean \n",
        "std_vals = std\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomApply([\n",
        "        transforms.RandomRotation(degrees=5),\n",
        "        transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
        "        transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)),\n",
        "    ], p=0.6),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean_vals, std=std_vals)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean_vals, std=std_vals)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torch\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Cuda available: {torch.cuda.is_available()}\")\n",
        "\n",
        "\n",
        "train_dir = 'D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train/'\n",
        "test_dir = 'D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test/'\n",
        "\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "train_targets = torch.tensor(train_dataset.targets, dtype=torch.long)\n",
        "class_sample_counts = torch.bincount(train_targets, minlength=len(train_dataset.classes))\n",
        "\n",
        "weights_per_class = 1.0 / (class_sample_counts.float() + 1e-3)\n",
        "sample_weights = weights_per_class[train_targets]\n",
        "\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(train_dataset),\n",
        "    replacement=True\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,\n",
        "    sampler=sampler,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "print(f\"Train dataset size: {len(train_dataset)} images\")\n",
        "print(f\"Test dataset size: {len(test_dataset)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "original_path = \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Converted\\Sagittal\\AD\\Sagittal_AD_018_S_4696_slice17.png\"\n",
        "processed_path = \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Processed\\Sagittal\\AD\\Sagittal_AD_018_S_4696_slice17.png\"\n",
        "\n",
        "original_image = Image.open(original_path)\n",
        "processed_image = Image.open(processed_path)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_image)\n",
        "plt.title(\"Processed\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "\n",
        "base_name = \"Sagittal_AD_018_S_4696_slice17.png\"\n",
        "original_path = f\"D:/Licenta/Datasets/ADNI_Oficial/Converted/Sagittal/AD/{base_name}\"\n",
        "processed_path = f\"D:/Licenta/Datasets/ADNI_Oficial/Processed/Sagittal/AD/{base_name}\"\n",
        "\n",
        "\n",
        "original_image = Image.open(original_path)\n",
        "processed_image = Image.open(processed_path)\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(240),               \n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(7),         \n",
        "    transforms.ColorJitter(brightness=0.05, contrast=0.05), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "transformed_tensor = train_transform(processed_image)\n",
        "transformed_image = transformed_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "transformed_image = transformed_image * std + mean\n",
        "transformed_image = transformed_image.clip(0, 1)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(processed_image)\n",
        "plt.title(\"Processed\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(transformed_image)\n",
        "plt.title(\"Augumented\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample, label = train_dataset[2]\n",
        "print(\"Sample shape:\", sample.shape)\n",
        "print(\"Label:\", label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swb0DFYMuu4U",
        "outputId": "39d5c691-d0be-4df3-d123-140e63774c73"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(\"Train files:\")\n",
        "print(os.listdir('D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train/'))\n",
        "\n",
        "print(\"Test files:\")\n",
        "print(os.listdir('D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test/'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMZmfE2_q2Ej"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNetModel(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=5):\n",
        "        super(ResNetModel, self).__init__()\n",
        "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "\n",
        "        for name, param in self.resnet.named_parameters():\n",
        "            if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        log_probs = F.log_softmax(inputs, dim=1)\n",
        "        probs = torch.exp(log_probs)\n",
        "\n",
        "        targets_one_hot = F.one_hot(targets, num_classes=inputs.size(1)).float().to(inputs.device)\n",
        "\n",
        "        focal_weight = (1 - probs) ** self.gamma\n",
        "        loss = -self.alpha * focal_weight * log_probs\n",
        "\n",
        "        loss = (loss * targets_one_hot).sum(dim=1)\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return loss.sum()\n",
        "        else:\n",
        "            return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "train_targets = torch.tensor(train_dataset.targets, dtype=torch.long)\n",
        "class_counts = torch.bincount(train_targets, minlength=len(class_names))\n",
        "num_classes = len(class_names)\n",
        "num_samples = len(train_targets)\n",
        "\n",
        "weights_per_class = num_samples / (num_classes * class_counts.float())\n",
        "class_weights = weights_per_class.to(device)\n",
        "\n",
        "print(\"Class distribution and computed weights:\")\n",
        "for idx, (count, weight) in enumerate(zip(class_counts.tolist(), weights_per_class.tolist())):\n",
        "    print(f\"  Class {class_names[idx]} — samples: {count}, weight: {weight:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(class_names, class_counts.cpu().numpy(), color='skyblue')\n",
        "plt.xlabel('Class Label')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Training Data Class Distribution')\n",
        "plt.grid(axis='y')\n",
        "plt.show()\n",
        "\n",
        "criterion = FocalLoss(alpha=1, gamma=2, reduction='mean')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp938nxGgNEq",
        "outputId": "9e3bcb17-a887-4751-f762-1a666179b8b5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingWarmRestarts\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "model = ResNetModel(pretrained=True, num_classes=5).to(device)\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=5e-5,                    \n",
        "    betas=(0.9, 0.9999),\n",
        "    weight_decay=2e-4\n",
        ")\n",
        "\n",
        "\n",
        "warmup_scheduler = LinearLR(optimizer, start_factor=0.1, total_iters=5)\n",
        "cosine_scheduler = CosineAnnealingWarmRestarts(\n",
        "    optimizer,\n",
        "    T_0=15,            \n",
        "    T_mult=2,\n",
        "    eta_min=1e-6\n",
        ")\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "\n",
        "scaler = GradScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTTQ8jnrq8YB"
      },
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.amp import autocast, GradScaler\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import os\n",
        "\n",
        "def train_model(model, train_dataloader, optimizer, criterion, num_epochs, scaler, scheduler=None, patience=12, use_amp=True, run_name='experiment_focal'):\n",
        "    writer = SummaryWriter(f'runs/{run_name}')\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "        correct_preds = 0\n",
        "        total_preds = 0\n",
        "\n",
        "        progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device.type == 'cuda' and use_amp)):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.detach().item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_preds += (predicted == labels).sum().item()\n",
        "            total_preds += labels.size(0)\n",
        "\n",
        "            current_loss = running_loss / (batch_idx + 1)\n",
        "            current_acc = correct_preds / total_preds\n",
        "            progress_bar.set_postfix(loss=current_loss, acc=current_acc)\n",
        "\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_dataloader)\n",
        "        epoch_acc = correct_preds / total_preds\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(epoch_loss)\n",
        "\n",
        "        writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n",
        "        writer.add_scalar('LearningRate', optimizer.param_groups[0]['lr'], epoch)\n",
        "\n",
        "        if epoch_loss < best_loss - 1e-4:\n",
        "            best_loss = epoch_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            epochs_no_improve = 0\n",
        "\n",
        "            os.makedirs('saved_models', exist_ok=True)\n",
        "            torch.save(model.state_dict(), f'saved_models/best_model__sagittal_epoch{epoch+1}.pth')\n",
        "            print(f\" Saved new best model at epoch {epoch+1} with loss {best_loss:.4f}\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\" Early stopping triggered at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        print(f\" Epoch {epoch+1}: Loss={epoch_loss:.4f}, Accuracy={epoch_acc*100:.2f}%\")\n",
        "\n",
        "    total_time = time.time() - total_start_time\n",
        "    print(f\"\\n Total Training Time: {total_time/60:.2f} minutes\")\n",
        "\n",
        "    torch.save(model.state_dict(), 'saved_models/last_model_sagittal.pth')\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    writer.close()\n",
        "\n",
        "    return model, train_losses, train_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFcs_9IerZ6X"
      },
      "outputs": [],
      "source": [
        "from torch.amp import autocast\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def evaluate_model(model, test_dataloader, criterion, device, writer=None, epoch=None, verbose=True, use_amp=True):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(test_dataloader, desc=\"Evaluating\", leave=False)\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with autocast(device_type=device.type, dtype=torch.float16, enabled=(device.type == 'cuda' and use_amp)):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            \n",
        "            loss_val = loss.item() if hasattr(loss, 'item') else float(loss)\n",
        "            running_loss += loss_val\n",
        "\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            all_preds.extend(predicted.cpu().tolist())\n",
        "            all_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "            current_loss = running_loss / (batch_idx + 1)\n",
        "            current_acc = accuracy_score(all_labels, all_preds)\n",
        "            progress_bar.set_postfix(loss=current_loss, acc=current_acc)\n",
        "\n",
        "    epoch_loss = running_loss / len(test_dataloader)\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n Final Evaluation — Loss: {epoch_loss:.4f}, Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "    if writer is not None and epoch is not None:\n",
        "        writer.add_scalar('Loss/test', epoch_loss, epoch)\n",
        "        writer.add_scalar('Accuracy/test', acc, epoch)\n",
        "\n",
        "    return epoch_loss, acc, all_preds, all_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "model, train_losses, train_accuracies = train_model(\n",
        "    model,\n",
        "    train_dataloader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    num_epochs=20,\n",
        "    scaler=scaler,\n",
        "    scheduler=scheduler,\n",
        "    patience=12\n",
        ")\n",
        "\n",
        "\n",
        "epoch_loss, acc, all_preds, all_labels = evaluate_model(\n",
        "    model,\n",
        "    test_dataloader,\n",
        "    criterion,\n",
        "    device\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(14, 6), dpi=100)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label=\"Train Loss\", color='red')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss per Epoch\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot([a * 100 for a in train_accuracies], label=\"Train Accuracy\", color='green')\n",
        "plt.axhline(acc * 100, color='blue', linestyle='--', linewidth=1.5, label='Test Accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Training Accuracy per Epoch\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "plt.suptitle(\"Training Progress Overview\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.savefig(\"training_progress.png\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(f\"\\nFinal Test Accuracy: {acc * 100:.2f}% | Final Test Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "with open(\"final_test_score.txt\", \"w\") as f:\n",
        "    f.write(f\"Final Test Accuracy: {acc * 100:.2f}%\\n\")\n",
        "    f.write(f\"Final Test Loss: {epoch_loss:.4f}\\n\")\n",
        "\n",
        "file_path = 'ResNet_Alzheimer_Sagittal_Multiclass.pth'\n",
        "torch.save(model.state_dict(), file_path)\n",
        "print(f\"Model saved at: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ResNetModel(pretrained=False, num_classes=5)  \n",
        "model.load_state_dict(torch.load('ResNet_Alzheimer_Sagittal_Multiclass.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dgPapZiAUnGl",
        "outputId": "68337050-1c66-4918-879f-66fb645348ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Filtered\\Sagittal\\Test\\CN\\Sagittal_CN_002_S_4213_slice17.png\"\n",
        "\n",
        "if not os.path.isfile(image_path):\n",
        "    print(\" Image not found. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean_vals, std=std_vals) \n",
        "])\n",
        "\n",
        "\n",
        "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]\n",
        "\n",
        "def predict_image(model, image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type=='cuda'):\n",
        "        outputs = model(image_tensor)\n",
        "        _, predicted_class = torch.max(outputs, 1)\n",
        "\n",
        "    return predicted_class.item(), outputs\n",
        "\n",
        "\n",
        "def display_prediction(image_path, predicted_class, outputs):\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {class_names[predicted_class]}\")\n",
        "    plt.show()\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    print(\"\\nScores per Class:\")\n",
        "    for i, prob in enumerate(probabilities[0]):\n",
        "        print(f\"  {class_names[i]:<5}: {prob.item():.4f}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "predicted_class, outputs = predict_image(model, image_path, device)\n",
        "display_prediction(image_path, predicted_class, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIm1DvRoV6Vp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "\n",
        "def show_random_predictions(model, test_dataloader, num_images=12, cols=4, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.eval()\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in test_dataloader:\n",
        "        all_images.append(images)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    if not all_images:\n",
        "        print(\" Test dataloader appears to be empty. Make sure it's not already exhausted.\")\n",
        "        return\n",
        "\n",
        "    all_images = torch.cat(all_images, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    total_images = len(all_images)\n",
        "    num_images = min(num_images, total_images)\n",
        "    indices = random.sample(range(total_images), num_images)\n",
        "\n",
        "    correct_list = []\n",
        "    wrong_list = []\n",
        "\n",
        "    for idx in indices:\n",
        "        image = all_images[idx]\n",
        "        label = all_labels[idx].item()\n",
        "\n",
        "       \n",
        "        input_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "            outputs = model(input_tensor)\n",
        "            _, predicted_class = torch.max(outputs, 1)\n",
        "\n",
        "        pred_idx = predicted_class.item()\n",
        "\n",
        "       \n",
        "        img_np = image.cpu().detach().numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img_np = img_np * std + mean\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "        entry = {\n",
        "            'image': img_np,\n",
        "            'pred': class_names[pred_idx],\n",
        "            'true': class_names[label],\n",
        "            'is_correct': pred_idx == label\n",
        "        }\n",
        "\n",
        "        if entry['is_correct']:\n",
        "            correct_list.append(entry)\n",
        "        else:\n",
        "            wrong_list.append(entry)\n",
        "\n",
        "    all_entries = wrong_list + correct_list  \n",
        "    total = len(all_entries)\n",
        "    rows = total // cols + int(total % cols != 0)\n",
        "\n",
        "    plt.figure(figsize=(cols * 3.5, rows * 3.5))\n",
        "\n",
        "    for i, entry in enumerate(all_entries):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(entry['image'])\n",
        "        title_color = 'green' if entry['is_correct'] else 'red'\n",
        "        plt.title(f\"Pred: {entry['pred']}\\nTrue: {entry['true']}\", color=title_color)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"Total images shown: {total}\")\n",
        "    print(f\"Correct predictions: {len(correct_list)}\")\n",
        "    print(f\"Wrong predictions:  {len(wrong_list)}\")\n",
        "\n",
        "    if wrong_list:\n",
        "        print(\"\\n🔍 Wrong predictions detail:\")\n",
        "        for idx, entry in enumerate(wrong_list, start=1):\n",
        "            print(f\"  {idx}. Predicted: {entry['pred']} | Actual: {entry['true']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_random_predictions(model, test_dataloader, num_images=100, cols=6, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "save_dir = 'results'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names, square=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Absolute Numbers)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_dir}/confusion_matrix_absolute_{timestamp}.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens',\n",
        "            xticklabels=class_names, yticklabels=class_names, square=True)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Normalized - Percentages)')\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{save_dir}/confusion_matrix_normalized_{timestamp}.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from datetime import datetime\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "\n",
        "predict_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def predict_random_image_from_folder(model, folder_path, device, save_fig=False):\n",
        "    images_list = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
        "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    if not images_list:\n",
        "        print(\"No images found in the selected folder.\")\n",
        "        return\n",
        "\n",
        "    image_path = random.choice(images_list)\n",
        "    print(f\"\\nSelected image: {image_path}\")\n",
        "\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = predict_transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "        outputs = model(input_tensor)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        top_probs, top_indices = torch.topk(probabilities, 3)\n",
        "\n",
        "  \n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted: {class_names[top_indices[0][0].item()]}\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_fig:\n",
        "        os.makedirs(\"random_predictions\", exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_path = f\"random_predictions/pred_{timestamp}.png\"\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        print(f\"Saved prediction image to: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n Top 3 Predictions:\")\n",
        "    for i in range(3):\n",
        "        idx = top_indices[0][i].item()\n",
        "        prob = top_probs[0][i].item()\n",
        "        print(f\"{class_names[idx]:<5}: {prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install grad-cam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "\n",
        "gradcam_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def generate_gradcam(model, image_path, device, save=False):\n",
        "    from pytorch_grad_cam import GradCAM\n",
        "    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "    from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "   \n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = gradcam_transform(image).unsqueeze(0).to(device)\n",
        "    image_np = np.array(image.resize((256, 256))).astype(np.float32) / 255.0\n",
        "\n",
        "    target_layers = [model.resnet.layer4[-1]]\n",
        "\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "        outputs = model(input_tensor)\n",
        "        _, pred_class = torch.max(outputs, 1)\n",
        "\n",
        "    targets = [ClassifierOutputTarget(pred_class.item())]\n",
        "\n",
        "    \n",
        "    cam = GradCAM(model=model, target_layers=target_layers)\n",
        "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]  \n",
        "\n",
        "    cam_image = show_cam_on_image(image_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cam_image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Grad-CAM - Predicted: {class_names[pred_class.item()]}\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save:\n",
        "        os.makedirs(\"gradcam_outputs\", exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        save_path = f\"gradcam_outputs/gradcam_{class_names[pred_class.item()]}_{timestamp}.png\"\n",
        "        plt.savefig(save_path, bbox_inches='tight')\n",
        "        print(f\" Grad-CAM saved to: {save_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_gradcam(model, \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Filtered\\Sagittal\\Test\\AD\\Sagittal_AD_019_S_4549_slice16.png\", device, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def top3_best_classes(model, test_dataloader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=list(range(len(class_names))))\n",
        "\n",
        "    class_totals = cm.sum(axis=1)\n",
        "    class_accuracy = np.zeros(len(class_names))\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        if class_totals[i] > 0:\n",
        "            class_accuracy[i] = cm[i, i] / class_totals[i]\n",
        "        else:\n",
        "            class_accuracy[i] = np.nan\n",
        "\n",
        "    sorted_indices = np.argsort(class_accuracy)[::-1]\n",
        "\n",
        "    print(\"\\n Top 3 Best Predicted Classes:\")\n",
        "    for idx in sorted_indices[:3]:\n",
        "        acc = class_accuracy[idx]\n",
        "        if not np.isnan(acc):\n",
        "            print(f\"  {class_names[idx]} — Accuracy: {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {class_names[idx]} — No samples in test set\")\n",
        "\n",
        "    print(\"\\nFull Class Accuracy:\")\n",
        "    for idx in sorted_indices:\n",
        "        acc = class_accuracy[idx]\n",
        "        if not np.isnan(acc):\n",
        "            print(f\"  {class_names[idx]:<5} — Accuracy: {acc:.4f}\")\n",
        "        else:\n",
        "            print(f\"  {class_names[idx]:<5} —  No samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top3_best_classes(model, test_dataloader, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def top_classes_sorted(model, test_dataloader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
        "\n",
        "    sorted_indices_desc = np.argsort(class_accuracy)[::-1]\n",
        "    \n",
        "    print(\"\\nTop Classes (Best to Worst):\")\n",
        "    for idx in sorted_indices_desc:\n",
        "        print(f\"{class_names[idx]} — Accuracy: {class_accuracy[idx]:.4f}\")\n",
        "\n",
        "    sorted_indices_asc = np.argsort(class_accuracy)\n",
        "\n",
        "    print(\"\\nTop Classes (Worst to Best):\")\n",
        "    for idx in sorted_indices_asc:\n",
        "        print(f\"{class_names[idx]} — Accuracy: {class_accuracy[idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_classes_sorted(model, test_dataloader, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "def plot_roc_auc(model, test_dataloader, device, class_names):\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                outputs = model(images)\n",
        "\n",
        "            all_outputs.append(outputs.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs)\n",
        "    all_labels = torch.cat(all_labels)\n",
        "\n",
        "    \n",
        "    all_labels_binarized = label_binarize(all_labels, classes=list(range(len(class_names))))\n",
        "\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(len(class_names)):\n",
        "        fpr[i], tpr[i], _ = roc_curve(all_labels_binarized[:, i], all_outputs[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "   \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for i in range(len(class_names)):\n",
        "        plt.plot(fpr[i], tpr[i], label=f\"{class_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--')  \n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve (One vs Rest)')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_roc_auc(model, test_dataloader, device, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class ResNet101_MRI(nn.Module):\n",
        "    def __init__(self, pretrained=True, num_classes=5):\n",
        "        super(ResNet101_MRI, self).__init__()\n",
        "        self.resnet = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "\n",
        "        for name, param in self.resnet.named_parameters():\n",
        "            if \"layer2\" in name or \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                param.requires_grad = True\n",
        "            else:\n",
        "                param.requires_grad = False\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.amp import GradScaler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_r101 = ResNet101_MRI(pretrained=True, num_classes=5).to(device)\n",
        "\n",
        "optimizer_r101 = optim.AdamW(\n",
        "    model_r101.parameters(),\n",
        "    lr=5e-5,\n",
        "    weight_decay=1e-4\n",
        ")\n",
        "\n",
        "\n",
        "scheduler_r101 = ReduceLROnPlateau(\n",
        "    optimizer_r101,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=4,\n",
        ")\n",
        "\n",
        "\n",
        "scaler_r101 = GradScaler()\n",
        "\n",
        "\n",
        "model_r101, train_losses_r101, train_acc_r101 = train_model(\n",
        "    model_r101,\n",
        "    train_dataloader,\n",
        "    optimizer_r101,\n",
        "    criterion,\n",
        "    num_epochs=20,\n",
        "    scaler=scaler_r101,\n",
        "    scheduler=scheduler_r101,  \n",
        "    patience=12\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_loss_r101, acc_r101, preds_r101, labels_r101 = evaluate_model(\n",
        "    model_r101,\n",
        "    test_dataloader,\n",
        "    criterion,\n",
        "    device\n",
        ")\n",
        "\n",
        "print(f\"\\nModel 2  - Final Test Accuracy: {acc_r101*100:.2f}% | Final Test Loss: {epoch_loss_r101:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = 'ResNet101_Alzheimer_Sagittal_Multiclass.pth'\n",
        "torch.save(model_r101.state_dict(), file_path)\n",
        "print(f\" ResNet101 model saved at: {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def ensemble_resnet50_resnet101(model_r50, model_r101, dataloader, device, class_names, w_r50=0.5, w_r101=0.5, save_report=False):\n",
        "    assert abs(w_r50 + w_r101 - 1.0) < 1e-5, \" Weights must sum to 1.0\"\n",
        "\n",
        "    model_r50.eval()\n",
        "    model_r101.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "                out_r50 = model_r50(images)\n",
        "                out_r101 = model_r101(images)\n",
        "\n",
        "            combined_logits = w_r50 * out_r50 + w_r101 * out_r101\n",
        "            _, predicted = torch.max(combined_logits, dim=1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
        "\n",
        "    print(f\"\\nEnsemble (ResNet50 + ResNet101) Accuracy: {acc * 100:.2f}%\")\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(report)\n",
        "\n",
        "    if save_report:\n",
        "        with open(\"ensemble_report.txt\", \"w\") as f:\n",
        "            f.write(f\"Ensemble Accuracy: {acc * 100:.2f}%\\n\\n\")\n",
        "            f.write(report)\n",
        "\n",
        "    return acc, all_preds, all_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_names = ['AD', 'CN', 'EMCI', 'LMCI', 'MCI']\n",
        "ensemble_acc, ensemble_preds, ensemble_labels = ensemble_resnet50_resnet101(\n",
        "    model_r50=model,\n",
        "    model_r101=model_r101,\n",
        "    dataloader=test_dataloader,\n",
        "    device=device,\n",
        "    class_names=class_names,\n",
        "    w_r50=0.4,\n",
        "    w_r101=0.6,\n",
        "    save_report=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "cm = confusion_matrix(ensemble_labels, ensemble_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Ensemble Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_acc = 0.0\n",
        "best_weights = (0.5, 0.5)\n",
        "\n",
        "for w_r50 in [0.1 * i for i in range(1, 10)]:\n",
        "    w_r101 = 1.0 - w_r50\n",
        "\n",
        "    acc_ens, _, _ = ensemble_resnet50_resnet101(\n",
        "        model_r50=model,\n",
        "        model_r101=model_r101,\n",
        "        dataloader=test_dataloader,\n",
        "        device=device,\n",
        "        class_names=class_names,\n",
        "        w_r50=w_r50,\n",
        "        w_r101=w_r101,\n",
        "        save_report=False  \n",
        "    )\n",
        "\n",
        "    print(f\" w_r50 = {w_r50:.1f} | w_r101 = {w_r101:.1f} → Accuracy: {acc_ens * 100:.2f}%\")\n",
        "\n",
        "    if acc_ens > best_acc:\n",
        "        best_acc = acc_ens\n",
        "        best_weights = (w_r50, w_r101)\n",
        "\n",
        "print(f\"\\n Best ensemble accuracy: {best_acc * 100:.2f}% with weights → ResNet50: {best_weights[0]:.1f}, ResNet101: {best_weights[1]:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "epoch_loss1, acc1, preds1, labels1 = evaluate_model(\n",
        "    model, test_dataloader, criterion, device\n",
        ")\n",
        "\n",
        "\n",
        "epoch_loss2, acc2, preds2, labels2 = evaluate_model(\n",
        "    model_r101, test_dataloader, criterion, device\n",
        ")\n",
        "\n",
        "\n",
        "acc_ens, preds_ens, labels_ens = ensemble_resnet50_resnet101(\n",
        "    model_r50=model,\n",
        "    model_r101=model_r101,\n",
        "    dataloader=test_dataloader,\n",
        "    device=device,\n",
        "    class_names=class_names,\n",
        "    w_r50=0.5,\n",
        "    w_r101=0.5\n",
        ")\n",
        "\n",
        "models_names = [\"ResNet50\", \"ResNet101\", \"Ensemble\"]\n",
        "accuracies = [acc1 * 100, acc2 * 100, acc_ens * 100]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(models_names, accuracies, color=[\"red\", \"blue\", \"green\"])\n",
        "plt.ylim(0, 100)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Model Comparison on Test Set\")\n",
        "\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height + 1,\n",
        "             f\"{height:.2f}%\", ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_gradcam_for_wrong_predictions(model, dataloader, device, class_names, model_type=\"resnet\", save_dir=\"gradcam_wrong_predictions\"):\n",
        "    model.eval()\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    transform_to_rgb = transforms.ToPILImage()\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        for i in range(len(images)):\n",
        "            if preds[i] != labels[i]:\n",
        "                image_tensor = images[i].unsqueeze(0)\n",
        "                input_tensor = image_tensor.to(device)\n",
        "\n",
        "                rgb_image = transform_to_rgb(images[i].cpu())\n",
        "\n",
        "                resize_dim = (256, 256) if model_type == \"resnet\" else (384, 384)\n",
        "                image_np = np.array(rgb_image.resize(resize_dim)).astype(np.float32) / 255.0\n",
        "\n",
        "                if model_type == \"resnet\":\n",
        "                    target_layers = [model.resnet.layer4[-1]]\n",
        "                elif model_type == \"efficientnet\":\n",
        "                    target_layers = [model.model.features[-1]]\n",
        "                else:\n",
        "                    raise ValueError(\"Unsupported model_type. Use 'resnet' or 'efficientnet'.\")\n",
        "\n",
        "                cam = GradCAM(model=model, target_layers=target_layers)\n",
        "                grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(preds[i].item())])[0]\n",
        "                cam_image = show_cam_on_image(image_np, grayscale_cam, use_rgb=True)\n",
        "\n",
        "                true_label = class_names[labels[i].item()]\n",
        "                pred_label = class_names[preds[i].item()]\n",
        "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
        "                filename = f\"true_{true_label}_pred_{pred_label}_{timestamp}.png\"\n",
        "                save_path = os.path.join(save_dir, filename)\n",
        "\n",
        "                plt.imsave(save_path, cam_image)\n",
        "                print(f\" Saved: {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "generate_gradcam_for_wrong_predictions(model, test_dataloader, device, class_names, model_type=\"resnet\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_random_ensemble_predictions(model_r50, model_r101, test_dataloader, class_names, device=None, w_r50=0.5, w_r101=0.5, num_images=12, cols=6):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    import random\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model_r50.eval()\n",
        "    model_r101.eval()\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "\n",
        "    for images, labels in test_dataloader:\n",
        "        all_images.append(images)\n",
        "        all_labels.append(labels)\n",
        "\n",
        "    all_images = torch.cat(all_images, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    total_images = len(all_images)\n",
        "    num_images = min(num_images, total_images)\n",
        "    indices = random.sample(range(total_images), num_images)\n",
        "\n",
        "    correct_list = []\n",
        "    wrong_list = []\n",
        "\n",
        "    for idx in indices:\n",
        "        image = all_images[idx]\n",
        "        label = all_labels[idx].item()\n",
        "        input_tensor = image.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=device.type == 'cuda'):\n",
        "            out_r50 = model_r50(input_tensor)\n",
        "            out_r101 = model_r101(input_tensor)\n",
        "            combined = w_r50 * out_r50 + w_r101 * out_r101\n",
        "            _, predicted_class = torch.max(combined, 1)\n",
        "\n",
        "        pred_idx = predicted_class.item()\n",
        "\n",
        "        img_np = image.cpu().detach().numpy().transpose((1, 2, 0))\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        img_np = img_np * std + mean\n",
        "        img_np = np.clip(img_np, 0, 1)\n",
        "\n",
        "        entry = {\n",
        "            'image': img_np,\n",
        "            'pred': class_names[pred_idx],\n",
        "            'true': class_names[label],\n",
        "            'is_correct': pred_idx == label\n",
        "        }\n",
        "\n",
        "        if entry['is_correct']:\n",
        "            correct_list.append(entry)\n",
        "        else:\n",
        "            wrong_list.append(entry)\n",
        "\n",
        "    all_entries = wrong_list + correct_list\n",
        "    rows = len(all_entries) // cols + int(len(all_entries) % cols != 0)\n",
        "\n",
        "    plt.figure(figsize=(cols * 3.5, rows * 3.5))\n",
        "\n",
        "    for i, entry in enumerate(all_entries):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        plt.imshow(entry['image'])\n",
        "        title_color = 'green' if entry['is_correct'] else 'red'\n",
        "        plt.title(f\"Pred: {entry['pred']}\\nTrue: {entry['true']}\", color=title_color)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"\\nSummary:\")\n",
        "    print(f\"Total images shown: {len(all_entries)}\")\n",
        "    print(f\"Correct predictions: {len(correct_list)}\")\n",
        "    print(f\"Wrong predictions:  {len(wrong_list)}\")\n",
        "\n",
        "    if wrong_list:\n",
        "        print(\"\\n🔍 Wrong predictions detail:\")\n",
        "        for i, entry in enumerate(wrong_list, 1):\n",
        "            print(f\"  {i}. Predicted: {entry['pred']} | Actual: {entry['true']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "show_random_ensemble_predictions(\n",
        "    model_r50=model,\n",
        "    model_r101=model_r101,\n",
        "    test_dataloader=test_dataloader,\n",
        "    class_names=class_names,\n",
        "    device=device,\n",
        "    w_r50=0.45,\n",
        "    w_r101=0.55,\n",
        "    num_images=100,\n",
        "    cols=6\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Filtered\\Sagittal\\Test\\CN\\Sagittal_CN_002_S_1261_slice24.png\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if not os.path.isfile(image_path):\n",
        "    print(\"Image not found. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean_vals, std=std_vals) \n",
        "])\n",
        "\n",
        "\n",
        "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]\n",
        "\n",
        "def predict_ensemble(model_r50, model_r101, image_path, device, w_r50=0.5, w_r101=0.5):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    model_r50.eval()\n",
        "    model_r101.eval()\n",
        "\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "        out_r50 = model_r50(image_tensor)\n",
        "        out_r101 = model_r101(image_tensor)\n",
        "        ensemble_output = w_r50 * out_r50 + w_r101 * out_r101\n",
        "        _, predicted_class = torch.max(ensemble_output, dim=1)\n",
        "\n",
        "    return predicted_class.item(), ensemble_output\n",
        "\n",
        "def display_prediction(image_path, predicted_class, outputs):\n",
        "    image = Image.open(image_path)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted (Ensemble): {class_names[predicted_class]}\")\n",
        "    plt.show()\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    print(\"\\nScores per Class:\")\n",
        "    for i, prob in enumerate(probabilities[0]):\n",
        "        print(f\"  {class_names[i]:<5}: {prob.item():.4f}\")\n",
        "\n",
        "model_r50 = model.to(device)\n",
        "model_r101 = model_r101.to(device)\n",
        "\n",
        "predicted_class, outputs = predict_ensemble(model_r50, model_r101, image_path, device)\n",
        "display_prediction(image_path, predicted_class, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "image_path = \"D:\\Licenta\\Datasets\\ADNI_Oficial\\Filtered\\Sagittal\\Test\\AD\\Sagittal_AD_019_S_4549_slice16.png\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if not os.path.isfile(image_path):\n",
        "    print(\"Image not found. Please check the path.\")\n",
        "    exit()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean_vals, std=std_vals)  \n",
        "])\n",
        "\n",
        "\n",
        "class_names = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]\n",
        "\n",
        "\n",
        "def predict_model(model, image_tensor, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
        "        outputs = model(image_tensor)\n",
        "        probs = F.softmax(outputs, dim=1)\n",
        "        top2 = torch.topk(probs, 2)\n",
        "        return outputs, probs, top2\n",
        "\n",
        "\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "image_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "model_r50 = model_r50.to(device)\n",
        "model_r101 = model_r101.to(device)\n",
        "\n",
        "\n",
        "out50, probs50, top2_50 = predict_model(model_r50, image_tensor, device)\n",
        "out101, probs101, top2_101 = predict_model(model_r101, image_tensor, device)\n",
        "\n",
        "ensemble_logits = 0.5 * out50 + 0.5 * out101\n",
        "probs_ens = F.softmax(ensemble_logits, dim=1)\n",
        "top2_ens = torch.topk(probs_ens, 2)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.title(\"MRI Image Prediction\")\n",
        "plt.show()\n",
        "\n",
        "def print_top2(name, top2, probs):\n",
        "    print(f\"\\n {name} Prediction:\")\n",
        "    for i in range(2):\n",
        "        idx = top2.indices[0][i].item()\n",
        "        conf = probs[0][idx].item()\n",
        "        print(f\"  {i+1}. {class_names[idx]} — {conf:.4f}\")\n",
        "\n",
        "print_top2(\"ResNet50\", top2_50, probs50)\n",
        "print_top2(\"ResNet101\", top2_101, probs101)\n",
        "print_top2(\"Ensemble\", top2_ens, probs_ens)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

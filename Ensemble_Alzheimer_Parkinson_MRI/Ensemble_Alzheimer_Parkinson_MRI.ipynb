{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python-headless\n",
    "%pip install opencv-python\n",
    "%pip install scikit-image\n",
    "%pip install scikit-learn\n",
    "%pip install tqdm\n",
    "%pip install sympy==1.13.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def compute_mean_std(data_dir, image_size=(256, 256), batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = 0.\n",
    "\n",
    "    for data, _ in loader:\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "        nb_samples += batch_samples\n",
    "\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "train_paths = {\n",
    "    \"Axial ADNI\": \"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Train\",\n",
    "    \"Sagittal ADNI\": \"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Train\",\n",
    "    \"Parkinson PPMI\": \"D:/Licenta/Datasets/PPMI_Oficial/Augmented/Train\"\n",
    "}\n",
    "\n",
    "for name, path in train_paths.items():\n",
    "    print(f\"\\nProcesare: {name}\")\n",
    "    mean, std = compute_mean_std(path)\n",
    "    print(f\"Mean : {mean.tolist()}\")\n",
    "    print(f\"Std  : {std.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "alz_classes = [\"AD\", \"CN\", \"EMCI\", \"LMCI\", \"MCI\"]\n",
    "park_classes = [\"Control\", \"PD\", \"Prodromal\", \"SWEDD\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform_axial = transforms.Compose([\n",
    "   transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.2006, 0.2006, 0.2006], [0.2396, 0.2396, 0.2396])\n",
    "])\n",
    "\n",
    "transform_sagittal = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.2487, 0.2487, 0.2487], [0.2599, 0.2599, 0.2599])\n",
    "])\n",
    "\n",
    "transform_parkinson = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.2514, 0.2514, 0.2514], [0.2475, 0.2475, 0.2475])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=5):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "\n",
    "        for name, param in self.resnet.named_parameters():\n",
    "            if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef13765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ResNet101_MRI(nn.Module):\n",
    "    def __init__(self, pretrained=True, num_classes=5):\n",
    "        super(ResNet101_MRI, self).__init__()\n",
    "        self.resnet = models.resnet101(weights=models.ResNet101_Weights.IMAGENET1K_V1 if pretrained else None)\n",
    "\n",
    "        for name, param in self.resnet.named_parameters():\n",
    "            if \"layer2\" in name or \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(in_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e89cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alz_ax_50 = ResNetModel(pretrained=False, num_classes=5)\n",
    "alz_ax_50.load_state_dict(torch.load(\"ResNet_Alzheimer_Axial_Multiclass.pth\"))\n",
    "alz_ax_50.to(device).eval()\n",
    "\n",
    "alz_ax_101 = ResNet101_MRI(pretrained=False, num_classes=5)\n",
    "alz_ax_101.load_state_dict(torch.load(\"ResNet101_Alzheimer_Axial_Multiclass.pth\"))\n",
    "alz_ax_101.to(device).eval()\n",
    "\n",
    "alz_sag_50 = ResNetModel(pretrained=False, num_classes=5)\n",
    "alz_sag_50.load_state_dict(torch.load(\"ResNet_Alzheimer_Sagittal_Multiclass.pth\"))\n",
    "alz_sag_50.to(device).eval()\n",
    "\n",
    "alz_sag_101 = ResNet101_MRI(pretrained=False, num_classes=5)\n",
    "alz_sag_101.load_state_dict(torch.load(\"ResNet101_Alzheimer_Sagittal_Multiclass.pth\"))\n",
    "alz_sag_101.to(device).eval()\n",
    "\n",
    "park_50 = ResNetModel(pretrained=False, num_classes=4)\n",
    "park_50.load_state_dict(torch.load(\"ResNet_Parkinson_Multiclass.pth\"))\n",
    "park_50.to(device).eval()\n",
    "\n",
    "park_101 = ResNet101_MRI(pretrained=False, num_classes=4)\n",
    "park_101.load_state_dict(torch.load(\"ResNet101_Parkinson_Multiclass.pth\"))\n",
    "park_101.to(device).eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae9f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_ensemble_fixed(model_r50, model_r101, img_tensor, class_names, w_r50=0.5, w_r101=0.5):\n",
    "   \n",
    "    model_r50.eval()\n",
    "    model_r101.eval()\n",
    "\n",
    "    with torch.no_grad(), torch.amp.autocast(device_type=img_tensor.device.type, enabled=(img_tensor.device.type == 'cuda')):\n",
    "        out_r50 = model_r50(img_tensor)\n",
    "        out_r101 = model_r101(img_tensor)\n",
    "        combined_logits = w_r50 * out_r50 + w_r101 * out_r101\n",
    "        probs = torch.softmax(combined_logits, dim=1)[0]\n",
    "        pred_idx = probs.argmax().item()\n",
    "        score = probs[pred_idx].item()\n",
    "        pred_label = class_names[pred_idx]\n",
    "    \n",
    "    return pred_idx, pred_label, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import torch\n",
    "\n",
    "def evaluate_ensemble_fixed(model_r50, model_r101, dataloader, device, class_names, w_r50=0.5, w_r101=0.5, save_report=False, report_path=\"ensemble_report.txt\"):\n",
    "    assert abs(w_r50 + w_r101 - 1.0) < 1e-5, \"Weights must sum to 1.0\"\n",
    "\n",
    "    model_r50.eval()\n",
    "    model_r101.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                out_r50 = model_r50(images)\n",
    "                out_r101 = model_r101(images)\n",
    "                combined_logits = w_r50 * out_r50 + w_r101 * out_r101\n",
    "                _, predicted = torch.max(combined_logits, dim=1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, target_names=class_names, digits=4)\n",
    "\n",
    "    print(f\"\\nEnsemble (ResNet50 + ResNet101) Accuracy: {acc * 100:.2f}%\")\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(report)\n",
    "\n",
    "    if save_report:\n",
    "        with open(report_path, \"w\") as f:\n",
    "            f.write(f\"Ensemble Accuracy: {acc * 100:.2f}%\\n\\n\")\n",
    "            f.write(report)\n",
    "\n",
    "    return acc, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "axial_loader = DataLoader(\n",
    "    datasets.ImageFolder(\"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Test\", transform=transform_axial),\n",
    "    batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "sagittal_loader = DataLoader(\n",
    "    datasets.ImageFolder(\"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test\", transform=transform_sagittal),\n",
    "    batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "parkinson_loader = DataLoader(\n",
    "    datasets.ImageFolder(\"D:/Licenta/Datasets/PPMI_Oficial/Augmented/Test\", transform=transform_parkinson),\n",
    "    batch_size=32, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dc1671",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Axial ---\")\n",
    "evaluate_ensemble_fixed(\n",
    "    model_r50=alz_ax_50,\n",
    "    model_r101=alz_ax_101,\n",
    "    dataloader=axial_loader,\n",
    "    device=device,\n",
    "    class_names=alz_classes,\n",
    "    w_r50=0.5,\n",
    "    w_r101=0.5,\n",
    "    save_report=True,\n",
    "    report_path=\"ensemble_axial_report.txt\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Sagittal ---\")\n",
    "evaluate_ensemble_fixed(\n",
    "    model_r50=alz_sag_50,\n",
    "    model_r101=alz_sag_101,\n",
    "    dataloader=sagittal_loader,\n",
    "    device=device,\n",
    "    class_names=alz_classes,\n",
    "    w_r50=0.5,\n",
    "    w_r101=0.5,\n",
    "    save_report=True,\n",
    "    report_path=\"ensemble_sagittal_report.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\n--- Parkinson ---\")\n",
    "evaluate_ensemble_fixed(\n",
    "    model_r50=park_50,\n",
    "    model_r101=park_101,\n",
    "    dataloader=parkinson_loader,\n",
    "    device=device,\n",
    "    class_names=park_classes,\n",
    "    w_r50=0.5,\n",
    "    w_r101=0.5,\n",
    "    save_report=True,\n",
    "    report_path=\"ensemble_parkinson_report.txt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c6c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def count_test_images(axial_dir, sagittal_dir, park_dir):\n",
    "    def count_images(folder):\n",
    "        count = 0\n",
    "        for cls in os.listdir(folder):\n",
    "            cls_path = os.path.join(folder, cls)\n",
    "            if os.path.isdir(cls_path):\n",
    "                count += sum(fname.endswith(\".png\") for fname in os.listdir(cls_path))\n",
    "        return count\n",
    "\n",
    "    axial_count = count_images(axial_dir)\n",
    "    sagittal_count = count_images(sagittal_dir)\n",
    "    park_count = count_images(park_dir)\n",
    "    total = axial_count + sagittal_count + park_count\n",
    "\n",
    "    print(f\"Axial: {axial_count} imagini\")\n",
    "    print(f\"Sagittal: {sagittal_count} imagini\")\n",
    "    print(f\"Parkinson: {park_count} imagini\")\n",
    "    print(f\"Total imagini în setul de test: {total}\")\n",
    "    return total\n",
    "\n",
    "def predict_from_folders_ensemble_visual(axial_dir, sagittal_dir, park_dir, total=100, cols=6, device='cuda'):\n",
    "    device = torch.device(device)\n",
    "\n",
    "    def collect_images_with_labels(folder, tag, classes):\n",
    "        images = []\n",
    "        for cls in os.listdir(folder):\n",
    "            cls_path = os.path.join(folder, cls)\n",
    "            if not os.path.isdir(cls_path): continue\n",
    "            for f in os.listdir(cls_path):\n",
    "                if f.endswith('.png'):\n",
    "                    images.append({\n",
    "                        \"path\": os.path.join(cls_path, f),\n",
    "                        \"label\": cls,\n",
    "                        \"tag\": tag,\n",
    "                        \"classes\": classes\n",
    "                    })\n",
    "        return images\n",
    "\n",
    "    axial_images = collect_images_with_labels(axial_dir, 'axial', alz_classes)\n",
    "    sagittal_images = collect_images_with_labels(sagittal_dir, 'sagittal', alz_classes)\n",
    "    park_images = collect_images_with_labels(park_dir, 'parkinson', park_classes)\n",
    "\n",
    "    print(\"\\n--- Evaluare Axial ---\")\n",
    "    axial_loader = DataLoader(ImageFolder(axial_dir, transform=transform_axial), batch_size=32, shuffle=False)\n",
    "    evaluate_ensemble_fixed(alz_ax_50, alz_ax_101, axial_loader, device, alz_classes, 0.5, 0.5, True, \"report_axial.txt\")\n",
    "\n",
    "    print(\"\\n--- Evaluare Sagittal ---\")\n",
    "    sagittal_loader = DataLoader(ImageFolder(sagittal_dir, transform=transform_sagittal), batch_size=32, shuffle=False)\n",
    "    evaluate_ensemble_fixed(alz_sag_50, alz_sag_101, sagittal_loader, device, alz_classes, 0.5, 0.5, True, \"report_sagittal.txt\")\n",
    "\n",
    "    print(\"\\n--- Evaluare Parkinson ---\")\n",
    "    parkinson_loader = DataLoader(ImageFolder(park_dir, transform=transform_parkinson), batch_size=32, shuffle=False)\n",
    "    evaluate_ensemble_fixed(park_50, park_101, parkinson_loader, device, park_classes, 0.5, 0.5, True, \"report_parkinson.txt\")\n",
    "\n",
    "    all_images = axial_images + sagittal_images + park_images\n",
    "    random.shuffle(all_images)\n",
    "    selected = all_images[:total]\n",
    "\n",
    "    rows = math.ceil(total / cols)\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols * 2.5, rows * 2.5))\n",
    "    axs = axs.flatten()\n",
    "    incorrect = []\n",
    "\n",
    "    for i, img_info in enumerate(selected):\n",
    "        img_path = img_info[\"path\"]\n",
    "        label = img_info[\"label\"]\n",
    "        tag = img_info[\"tag\"]\n",
    "        classes = img_info[\"classes\"]\n",
    "\n",
    "        img = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        if tag == 'axial':\n",
    "            transform = transform_axial\n",
    "            model_r50, model_r101 = alz_ax_50, alz_ax_101\n",
    "        elif tag == 'sagittal':\n",
    "            transform = transform_sagittal\n",
    "            model_r50, model_r101 = alz_sag_50, alz_sag_101\n",
    "        else:\n",
    "            transform = transform_parkinson\n",
    "            model_r50, model_r101 = park_50, park_101\n",
    "\n",
    "        img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "        pred_idx, pred_label, score = predict_with_ensemble_fixed(model_r50, model_r101, img_tensor, classes)\n",
    "\n",
    "        is_correct = (pred_label == label)\n",
    "        color = \"green\" if is_correct else \"red\"\n",
    "        title = f\"{tag} | Pred: {pred_label}\\nReal: {label}\"\n",
    "\n",
    "        axs[i].imshow(img, cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "        axs[i].set_title(title, fontsize=7, color=color)\n",
    "\n",
    "        if not is_correct:\n",
    "            incorrect.append((img_path, label, pred_label, score))\n",
    "\n",
    "    for j in range(len(selected), len(axs)):\n",
    "        axs[j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Predicții Corecte (Verde) / Greșite (Roșu)\", fontsize=16)\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nTotal greșite în subsetul afișat: {len(incorrect)} din {total}\")\n",
    "    accuracy = 1 - len(incorrect) / total\n",
    "    print(f\"Acuratețea pe subsetul afișat: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    if incorrect:\n",
    "        print(\"\\nExemple greșite:\")\n",
    "        for path, real, pred, score in incorrect:\n",
    "            print(f\"{os.path.basename(path)} | Real: {real} | Pred: {pred} | Score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e692b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test_images(\n",
    "    \"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Test\",\n",
    "    \"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test\",\n",
    "    \"D:/Licenta/Datasets/PPMI_Oficial/Augmented/Test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_from_folders_ensemble_visual(\n",
    "    axial_dir=\"D:/Licenta/Datasets/ADNI_Oficial/Processed/Axial/Test\",\n",
    "    sagittal_dir=\"D:/Licenta/Datasets/ADNI_Oficial/Filtered/Sagittal/Test\",\n",
    "    park_dir=\"D:/Licenta/Datasets/PPMI_Oficial/Augmented/Test\",\n",
    "    total=6028,\n",
    "    cols=5,\n",
    "    device='cuda'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

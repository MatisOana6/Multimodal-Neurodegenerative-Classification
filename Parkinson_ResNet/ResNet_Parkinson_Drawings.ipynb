{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FrbABV01cs7",
        "outputId": "8773f5e6-4ec0-4bb3-bf1e-760f4c449295"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)  \n",
        "print(torch.cuda.is_available())  \n",
        "print(torch.cuda.current_device())  \n",
        "print(torch.cuda.get_device_name(0)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install opencv-python-headless\n",
        "%pip install opencv-python\n",
        "%pip install scikit-image\n",
        "%pip install scikit-learn\n",
        "%pip install tqdm\n",
        "%pip install sympy==1.13.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dir = \"D:/Licenta/Datasets/Parkinson_s Drawings/augmented_combined/\"\n",
        "train_dir = os.path.join(base_dir, \"training\")\n",
        "test_dir = os.path.join(base_dir, \"testing\")\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 15\n",
        "lr = 1e-4\n",
        "img_size = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPCk7WN9q1LZ",
        "outputId": "71fffc9c-917d-44ce-e22a-bd2b15bffe82"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "print(\"Classes:\", train_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = correct / total\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, marker='o')\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(train_accuracies, marker='o', color='green')\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "        y_pred.extend(preds)\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\n CLASSIFICATION REPORT:\")\n",
        "print(classification_report(y_true, y_pred, target_names=train_dataset.classes))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"resnet50_parkinson.pth\")\n",
        "print(\"Model salvat în resnet50_parkinson.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "\n",
        "images_list = []\n",
        "labels_list = []\n",
        "preds_list = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images.to(device))\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        images_list.extend(images)\n",
        "        labels_list.extend(labels)\n",
        "        preds_list.extend(preds.cpu())\n",
        "\n",
        "\n",
        "num_samples = 100 \n",
        "\n",
        "cols = 5\n",
        "rows = num_samples // cols\n",
        "plt.figure(figsize=(3 * cols, 3 * rows))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    idx = random.randint(0, len(images_list) - 1)\n",
        "    img = images_list[idx].permute(1, 2, 0).numpy()\n",
        "    img = (img * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "    true_label = class_names[labels_list[idx]]\n",
        "    pred_label = class_names[preds_list[idx]]\n",
        "\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"T:{true_label}\\nP:{pred_label}\", fontsize=8,\n",
        "              color='green' if true_label == pred_label else 'red')\n",
        "\n",
        "plt.suptitle(\"Real vs Predicted (100 random)\", fontsize=18)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wrong_idx = [i for i in range(len(preds_list)) if preds_list[i] != labels_list[i]]\n",
        "\n",
        "print(f\"Total greșeli: {len(wrong_idx)} din {len(preds_list)}\")\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "for i, idx in enumerate(wrong_idx[:5]):  \n",
        "    img = images_list[idx].permute(1, 2, 0).numpy()\n",
        "    img = (img * 0.5 + 0.5).clip(0, 1)\n",
        "\n",
        "    true_label = class_names[labels_list[idx]]\n",
        "    pred_label = class_names[preds_list[idx]]\n",
        "\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"T: {true_label}\\nP: {pred_label}\", color='red')\n",
        "\n",
        "plt.suptitle(\"Predicții greșite\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(labels_list, preds_list)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import normalize, resize, to_tensor\n",
        "from torchvision.transforms import ToPILImage\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchcam.methods import GradCAM\n",
        "\n",
        "cam_extractor = GradCAM(model, target_layer=\"layer4\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def show_gradcam(img_tensor, label_idx):\n",
        "    img_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "    out = model(img_tensor)\n",
        "    pred_class = out.argmax().item()\n",
        "    activation_map = cam_extractor(pred_class, out)\n",
        "\n",
        "    cam = activation_map[0].cpu().numpy()\n",
        "    cam = np.uint8(255 * cam.squeeze())  \n",
        "    cam = cv2.resize(cam, (img_tensor.shape[3], img_tensor.shape[2]))\n",
        "\n",
        "\n",
        "    heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "    img_np = img_tensor.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
        "    img_np = (img_np * 0.5 + 0.5).clip(0, 1)\n",
        "    img_np = np.uint8(img_np * 255)\n",
        "    overlay = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "    plt.imshow(overlay)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"True: {class_names[label_idx]} | Pred: {class_names[pred_class]}\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_idx = random.randint(0, len(images_list)-1)\n",
        "sample_image = images_list[sample_idx]\n",
        "sample_label = labels_list[sample_idx]\n",
        "\n",
        "show_gradcam(sample_image, sample_label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_parkinson_clean",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
